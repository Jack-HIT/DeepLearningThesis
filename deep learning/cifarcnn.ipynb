{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import keras\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model  \n",
    "%matplotlib inline\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense,Conv2D,Activation,BatchNormalization,MaxPool2D,Flatten,Input,ZeroPadding2D,MaxPooling2D,concatenate,AveragePooling2D,Dropout,GlobalAveragePooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "import keras.callbacks as kcallbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4b5b703780>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可以随机选择一个将图片数据可视化\n",
    "img=X_train[19]\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n",
      "(10000, 10)\n",
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# 将y数据处理成one-hot编码的数据\n",
    "y_train=to_categorical(y_train,num_classes=10)\n",
    "y_test=to_categorical(y_test,num_classes=10)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "# 将X数据进行归一化，方便训练的时候算法收敛\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train=X_train/255\n",
    "X_test=X_test/255\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义一些初始化的变量\n",
    "INPUT_SHAPE=(32,32,3)\n",
    "NUM_CLASS=10\n",
    "BATCHSIZE=128\n",
    "EPOCHS=100\n",
    "SAVEPATH='./'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lexnet(input_shape,num_class,batchsize,epochs,savepath='./cifar10_lexnet_model.hdf5'):\n",
    "    # create model\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(filters=6, kernel_size=(5,5), padding='valid', input_shape=input_shape, activation='tanh'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(filters=16, kernel_size=(5,5), padding='valid', activation='tanh'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    #下面就是全连接层了\n",
    "    model.add(Dense(120, activation='tanh'))\n",
    "    model.add(Dense(84, activation='tanh'))\n",
    "    model.add(Dense(num_class, activation='softmax'))\n",
    "    #定义一下优化的方法\n",
    "    opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    #compile model\n",
    "    #使用交叉熵(cross entropy)作为损失函数\n",
    "    model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    #train model\n",
    "    earlyStopping=kcallbacks.EarlyStopping(monitor='val_acc', patience=2, verbose=1, mode='auto')\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(filepath=savepath, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "    model.fit(X_train,y_train,batch_size=batchsize,epochs=epochs,verbose=1,\n",
    "              validation_data=(X_test,y_test),shuffle=True,callbacks=[earlyStopping,saveBestModel])\n",
    "   #reload model\n",
    "    model=load_model(savepath)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 1.6341 - acc: 0.4130 - val_loss: 1.4705 - val_acc: 0.4809\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.48090, saving model to ./cifar10_lexnet_model.hdf5\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.3711 - acc: 0.5122 - val_loss: 1.4181 - val_acc: 0.4953\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.48090 to 0.49530, saving model to ./cifar10_lexnet_model.hdf5\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.2805 - acc: 0.5445 - val_loss: 1.2533 - val_acc: 0.5574\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.49530 to 0.55740, saving model to ./cifar10_lexnet_model.hdf5\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.2083 - acc: 0.5727 - val_loss: 1.2015 - val_acc: 0.5803\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.55740 to 0.58030, saving model to ./cifar10_lexnet_model.hdf5\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.1580 - acc: 0.5927 - val_loss: 1.1652 - val_acc: 0.5889\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.58030 to 0.58890, saving model to ./cifar10_lexnet_model.hdf5\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.1161 - acc: 0.6057 - val_loss: 1.1412 - val_acc: 0.5968\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.58890 to 0.59680, saving model to ./cifar10_lexnet_model.hdf5\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.0711 - acc: 0.6244 - val_loss: 1.1346 - val_acc: 0.5976\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.59680 to 0.59760, saving model to ./cifar10_lexnet_model.hdf5\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.0311 - acc: 0.6367 - val_loss: 1.1104 - val_acc: 0.6131\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.59760 to 0.61310, saving model to ./cifar10_lexnet_model.hdf5\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.9985 - acc: 0.6505 - val_loss: 1.1229 - val_acc: 0.6104\n",
      "\n",
      "Epoch 00009: val_acc did not improve\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 0.9658 - acc: 0.6608 - val_loss: 1.0715 - val_acc: 0.6236\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.61310 to 0.62360, saving model to ./cifar10_lexnet_model.hdf5\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 0.9357 - acc: 0.6723 - val_loss: 1.0492 - val_acc: 0.6377\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.62360 to 0.63770, saving model to ./cifar10_lexnet_model.hdf5\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.9110 - acc: 0.6822 - val_loss: 1.0781 - val_acc: 0.6264\n",
      "\n",
      "Epoch 00012: val_acc did not improve\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 0.8801 - acc: 0.6936 - val_loss: 1.0518 - val_acc: 0.6371\n",
      "\n",
      "Epoch 00013: val_acc did not improve\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "lexnet_model=lexnet(INPUT_SHAPE,NUM_CLASS,BATCHSIZE,EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 6)         456       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 62,006\n",
      "Trainable params: 62,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10000/10000 [==============================] - 1s 50us/step\n",
      "lexnet的评估结果是\n",
      "Total loss on Testing Set: 1.0492245069503785\n",
      "Accuracy of Testing Set: 0.6377\n"
     ]
    }
   ],
   "source": [
    "lexnet_model.summary()\n",
    "score=lexnet_model.evaluate(X_test,y_test)\n",
    "print('lexnet的评估结果是')\n",
    "print(\"Total loss on Testing Set:\", score[0])\n",
    "print(\"Accuracy of Testing Set:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测的结果是： 3\n",
      "真实的结果是： 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4b2ff42cc0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lexnet_model=load_model('./cifar10_lexnet_model.hdf5')\n",
    "X_test_t=X_test[8].reshape((-1,32,32,3))\n",
    "y_hat=lexnet_model.predict(X_test_t).argmax()\n",
    "print('预测的结果是：',y_hat)\n",
    "print('真实的结果是：',y_test[8].argmax())\n",
    "plt.imshow(X_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def alexnet(input_shape,num_class,batchsize,epochs,savepath=SAVEPATH+'cifar10_alexnet_model.hdf5'):\n",
    "    model = Sequential()  \n",
    "    model.add(Conv2D(96,(11,11),strides=(4,4),input_shape=input_shape,padding='valid',activation='relu',kernel_initializer='uniform'))  \n",
    "    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))  \n",
    "    model.add(Conv2D(256,(5,5),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))  \n",
    "    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))  \n",
    "    model.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))  \n",
    "    model.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))  \n",
    "    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))  \n",
    "    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))  \n",
    "    model.add(Flatten())  \n",
    "    model.add(Dense(4096,activation='relu'))  \n",
    "    model.add(Dropout(0.5))  \n",
    "    model.add(Dense(4096,activation='relu'))  \n",
    "    model.add(Dropout(0.5))  \n",
    "    model.add(Dense(num_class,activation='softmax'))  \n",
    "    #定义一下优化的方法\n",
    "    opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    #compile一下模型\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])  \n",
    "    #train model\n",
    "    earlyStopping=kcallbacks.EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(filepath=savepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "    model.fit(X_train,y_train,batch_size=batchsize,epochs=epochs,verbose=1,\n",
    "              validation_data=(X_test,y_test),shuffle=True,callbacks=[earlyStopping,saveBestModel])\n",
    "    #reload model\n",
    "    model=load_model(savepath)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.6179 - acc: 0.4204 - val_loss: 1.4141 - val_acc: 0.4915\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.49150, saving model to ./cifar10_lexnet_model.hdf5\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.3499 - acc: 0.5197 - val_loss: 1.3080 - val_acc: 0.5343\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.49150 to 0.53430, saving model to ./cifar10_lexnet_model.hdf5\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.2499 - acc: 0.5579 - val_loss: 1.2465 - val_acc: 0.5570\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.53430 to 0.55700, saving model to ./cifar10_lexnet_model.hdf5\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.1785 - acc: 0.5840 - val_loss: 1.1925 - val_acc: 0.5735\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.55700 to 0.57350, saving model to ./cifar10_lexnet_model.hdf5\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.1223 - acc: 0.6043 - val_loss: 1.1817 - val_acc: 0.5887\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.57350 to 0.58870, saving model to ./cifar10_lexnet_model.hdf5\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.0768 - acc: 0.6200 - val_loss: 1.1241 - val_acc: 0.6054\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.58870 to 0.60540, saving model to ./cifar10_lexnet_model.hdf5\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.0377 - acc: 0.6344 - val_loss: 1.1260 - val_acc: 0.6094\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.60540 to 0.60940, saving model to ./cifar10_lexnet_model.hdf5\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.9961 - acc: 0.6503 - val_loss: 1.1194 - val_acc: 0.6086\n",
      "\n",
      "Epoch 00008: val_acc did not improve\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 0.9624 - acc: 0.6618 - val_loss: 1.1135 - val_acc: 0.6117\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.60940 to 0.61170, saving model to ./cifar10_lexnet_model.hdf5\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 0.9363 - acc: 0.6722 - val_loss: 1.1000 - val_acc: 0.6154\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.61170 to 0.61540, saving model to ./cifar10_lexnet_model.hdf5\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 0.9023 - acc: 0.6837 - val_loss: 1.0734 - val_acc: 0.6315\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.61540 to 0.63150, saving model to ./cifar10_lexnet_model.hdf5\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 0.8745 - acc: 0.6951 - val_loss: 1.0807 - val_acc: 0.6272\n",
      "\n",
      "Epoch 00012: val_acc did not improve\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.8472 - acc: 0.7034 - val_loss: 1.0781 - val_acc: 0.6258\n",
      "\n",
      "Epoch 00013: val_acc did not improve\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "alexnet_model=lexnet(INPUT_SHAPE,NUM_CLASS,BATCHSIZE,EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 64us/step\n",
      "alexnet_model的评估结果是\n",
      "Total loss on Testing Set: 1.0734142539024354\n",
      "Accuracy of Testing Set: 0.6315\n"
     ]
    }
   ],
   "source": [
    "score=alexnet_model.evaluate(X_test,y_test)\n",
    "print('alexnet_model的评估结果是')\n",
    "print(\"Total loss on Testing Set:\", score[0])\n",
    "print(\"Accuracy of Testing Set:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 接下来训练vgg网络\n",
    "因为vgg网络要求输入不要太小，所以我们需要把输入数据resize成64,64,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_vgg=[cv2.resize(img,(64,64)) for img in X_train]\n",
    "X_train_vgg=np.array(X_train_vgg)\n",
    "X_test_vgg=[cv2.resize(img,(64,64)) for img in X_test]\n",
    "X_test_vgg=np.array(X_test_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg19net(input_shape,num_class,batchsize,epochs,savepath=SAVEPATH+'cifar10_vgg_model.hdf5'):\n",
    "    model_vgg19=VGG19(include_top=False,weights='imagenet',input_shape=(64,64,3))\n",
    "    model=Flatten(name='flatten')(model_vgg19.output)\n",
    "    model=Dense(10,activation='softmax')(model)\n",
    "    model_vgg19_clair=Model(model_vgg19.input,model,name='vgg19')\n",
    "    #定义一下优化的方法\n",
    "    opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    #compile一下模型\n",
    "    model_vgg19_clair.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])  \n",
    "    #train model\n",
    "    earlyStopping=kcallbacks.EarlyStopping(monitor='val_acc', patience=2, verbose=1, mode='auto')\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(filepath=savepath, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "    model_vgg19_clair.fit(X_train_vgg,y_train,batch_size=batchsize,epochs=epochs,verbose=1,\n",
    "              validation_data=(X_test_vgg,y_test),shuffle=True,callbacks=[earlyStopping,saveBestModel])\n",
    "    #reload model\n",
    "    vgg19_clair_model=load_model(savepath)\n",
    "    return vgg19_clair_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 2.0941 - acc: 0.1859 - val_loss: 1.7908 - val_acc: 0.2843\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.28430, saving model to ./cifar10_vgg_model.hdf5\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 75s 2ms/step - loss: 1.6751 - acc: 0.3522 - val_loss: 1.4098 - val_acc: 0.4645\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.28430 to 0.46450, saving model to ./cifar10_vgg_model.hdf5\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 79s 2ms/step - loss: 1.3100 - acc: 0.5158 - val_loss: 1.1945 - val_acc: 0.5570\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.46450 to 0.55700, saving model to ./cifar10_vgg_model.hdf5\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 77s 2ms/step - loss: 1.0722 - acc: 0.6087 - val_loss: 0.9738 - val_acc: 0.6488\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.55700 to 0.64880, saving model to ./cifar10_vgg_model.hdf5\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 0.9068 - acc: 0.6720 - val_loss: 0.9213 - val_acc: 0.6789\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.64880 to 0.67890, saving model to ./cifar10_vgg_model.hdf5\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 77s 2ms/step - loss: 0.7931 - acc: 0.7186 - val_loss: 0.8615 - val_acc: 0.7034\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.67890 to 0.70340, saving model to ./cifar10_vgg_model.hdf5\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 0.7079 - acc: 0.7510 - val_loss: 0.7680 - val_acc: 0.7348\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.70340 to 0.73480, saving model to ./cifar10_vgg_model.hdf5\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 0.6335 - acc: 0.7797 - val_loss: 0.7195 - val_acc: 0.7553\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.73480 to 0.75530, saving model to ./cifar10_vgg_model.hdf5\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 0.5677 - acc: 0.8031 - val_loss: 0.6928 - val_acc: 0.7680\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.75530 to 0.76800, saving model to ./cifar10_vgg_model.hdf5\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 0.5127 - acc: 0.8241 - val_loss: 0.6778 - val_acc: 0.7712\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.76800 to 0.77120, saving model to ./cifar10_vgg_model.hdf5\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 0.4507 - acc: 0.8452 - val_loss: 0.6950 - val_acc: 0.7760\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.77120 to 0.77600, saving model to ./cifar10_vgg_model.hdf5\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 0.4165 - acc: 0.8572 - val_loss: 0.6736 - val_acc: 0.7796\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.77600 to 0.77960, saving model to ./cifar10_vgg_model.hdf5\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 0.3801 - acc: 0.8698 - val_loss: 0.6553 - val_acc: 0.7887\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.77960 to 0.78870, saving model to ./cifar10_vgg_model.hdf5\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 0.3410 - acc: 0.8836 - val_loss: 0.6558 - val_acc: 0.7893\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.78870 to 0.78930, saving model to ./cifar10_vgg_model.hdf5\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 0.3266 - acc: 0.8884 - val_loss: 0.6661 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.78930 to 0.79400, saving model to ./cifar10_vgg_model.hdf5\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 0.2856 - acc: 0.9024 - val_loss: 0.6672 - val_acc: 0.7928\n",
      "\n",
      "Epoch 00016: val_acc did not improve\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 0.2630 - acc: 0.9113 - val_loss: 0.7076 - val_acc: 0.7924\n",
      "\n",
      "Epoch 00017: val_acc did not improve\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "vgg_model=vgg19net((64,64,3),NUM_CLASS,BATCHSIZE,EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 7s 707us/step\n",
      "vgg_model的评估结果是\n",
      "Total loss on Testing Set: 0.6523544511795044\n",
      "Accuracy of Testing Set: 0.8042\n"
     ]
    }
   ],
   "source": [
    "score=vgg_model.evaluate(X_test_vgg,y_test)\n",
    "print('vgg_model的评估结果是')\n",
    "print(\"Total loss on Testing Set:\", score[0])\n",
    "print(\"Accuracy of Testing Set:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 接下来是google的inceptionv3\n",
    "输入采取的是139,139,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "import numpy as np\n",
    "X_train_inception=[cv2.resize(img,(139,139)) for img in X_train]\n",
    "X_train_inception=np.array(X_train_inception)\n",
    "X_test_inception=[cv2.resize(img,(139,139)) for img in X_test]\n",
    "X_test_inception=np.array(X_test_inception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 139, 139, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_inception.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inceptionv3(input_shape,num_class,batchsize,epochs,savepath=SAVEPATH+'inceptionv3.hdf5'):\n",
    "    base_model=InceptionV3(include_top=False,weights='imagenet',input_shape=input_shape)\n",
    "    # add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    # and a logistic layer -- let's say we have 10classes\n",
    "    predictions = Dense(num_class, activation='softmax')(x)\n",
    "    model=Model(base_model.input,predictions,name='inceptionv3')\n",
    "    #定义一下优化的方法\n",
    "    opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    #compile一下模型\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])  \n",
    "    #train model\n",
    "    earlyStopping=kcallbacks.EarlyStopping(monitor='val_acc', patience=2, verbose=1, mode='auto')\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(filepath=savepath, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "    model.fit(X_train_inception,y_train,batch_size=batchsize,epochs=epochs,verbose=1,\n",
    "              validation_data=(X_test_inception,y_test),shuffle=True,callbacks=[earlyStopping,saveBestModel])\n",
    "    #reload model\n",
    "    model=load_model(savepath)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 172s 3ms/step - loss: 0.5765 - acc: 0.8111 - val_loss: 1.1327 - val_acc: 0.6781\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.67810, saving model to ./inceptionv3.hdf5\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 173s 3ms/step - loss: 0.2956 - acc: 0.9027 - val_loss: 1.2048 - val_acc: 0.6762\n",
      "\n",
      "Epoch 00002: val_acc did not improve\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 173s 3ms/step - loss: 0.2145 - acc: 0.9283 - val_loss: 0.4737 - val_acc: 0.8514\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.67810 to 0.85140, saving model to ./inceptionv3.hdf5\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 173s 3ms/step - loss: 0.1634 - acc: 0.9457 - val_loss: 0.4037 - val_acc: 0.8751\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.85140 to 0.87510, saving model to ./inceptionv3.hdf5\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 173s 3ms/step - loss: 0.1314 - acc: 0.9561 - val_loss: 0.5581 - val_acc: 0.8434\n",
      "\n",
      "Epoch 00005: val_acc did not improve\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 173s 3ms/step - loss: 0.1132 - acc: 0.9615 - val_loss: 0.5369 - val_acc: 0.8494\n",
      "\n",
      "Epoch 00006: val_acc did not improve\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "inceptionv3_model=inceptionv3((139,139,3),NUM_CLASS,BATCHSIZE,EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 17s 2ms/step\n",
      "inceptionv3_model的评估结果是\n",
      "Total loss on Testing Set: 0.4036563428163528\n",
      "Accuracy of Testing Set: 0.8751\n"
     ]
    }
   ],
   "source": [
    "score=inceptionv3_model.evaluate(X_test_inception,y_test)\n",
    "print('inceptionv3_model的评估结果是')\n",
    "print(\"Total loss on Testing Set:\", score[0])\n",
    "print(\"Accuracy of Testing Set:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
